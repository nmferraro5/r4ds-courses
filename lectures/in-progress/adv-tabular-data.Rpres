Advanced Tabular Data Manipulation	
========================================================
author: Alejandro Schuler, adapted from Steve Bagley and based on R for Data Science by Hadley Wickham
date: July 2020
transition: none
width: 1680
height: 1050

- compute cumulative, offset, and sliding-window transformations
- simultaneously transform or summarize multiple columns
- transform between long and wide data formats
- combine multiple data frames using joins on one or more columns

```{r include=FALSE}
## better font size for slides
library(tidyverse)
theme_set(theme_grey(base_size = 22))
opts_chunk$set(collapse=TRUE,tidy=TRUE,prompt=FALSE,comment=NA,cache=FALSE)
opts_chunk$set(error=TRUE,warning=TRUE,message=TRUE)
```
<style>
.small-code pre code {
  font-size: 0.5em;
}
</style>

Window transformations
===
type: section

Offsets
===
incremental: true

- `lead()` and `lag()` return either forward- or backward-shifted versions of their input vectors
```{r}
lead(c(1,2,3))
lag(c(1,2,3))
```

- This is most useful to compute offsets
```{r, tidy=F}
scores = tibble(
  day = c(1,2,3,4),
  score = c(72, 87, 94, 99)
)
```

```{r, tidy=F}
scores %>%
  mutate(daily_improvement = score - lag(score))
```

Exercise: multiple offsets
===
type: prompt

```{r, tidy=F}
scores = tibble(
  week = c(1,1,2,2,3,3,4,4),
  weekday = c("M","F","M","F","M","F","M","F"),
  score = c(72, 71, 80, 87, 94, 82, 99, 98)
)
```
Let's say you want to compute the improvement in scores within weekdays from one week to the next
(i.e. comparing week 1 Monday to week 2 Monday and week 1 Friday to week 2 Friday)

1. Figure out a way to do this using `lead()` or `lag()` in a single `mutate()` statement (hint: check the documentation).
2. Figure out a different way to do this with `group_by()` instead. Which seems more natural or robust to you? Why?
3. In both solutions you end up with some `NA`s since the "week 0" scores are unknown. If we wanted to assume that the week 0 scores would be the same as the week 1 scores, how might we modify our code to reflect that in order to make sure we don't get `NA`s in the result?

Rolling functions
===

- `slide_vec` applies a function using a sliding window across a vector (sometimes called a "rolling" function)

```{r}
library("slider")
numbers = c(9,6,8,4,7,3,8,4,2,1,3,2)
slide_vec(numbers, sum, .after=3, .step=2)
```

- the `.after` argument specifies how many elements after the "index" element are included in the rolling window
- `.step` specifies how to move from one index element to the next

***

![](https://www.oreilly.com/library/view/introduction-to-apache/9781491977132/assets/itaf_0406.png)

Rolling functions
===
```{r, tidy=F}
profits = tibble(
  day = c(1,2,3,4),
  profit = c(12, 40, 19, 13)
)
```

- `.before` is the backward-looking equivalent of `.after`

```{r, tidy=F}
profits %>%
  mutate(avg_2_day_profit = slide_vec(profit, mean, .before=1))
```

Cumulative functions
===
incremental: true

- A cumulative function is like a rolling window function except that the window expands with each iteration instead of shifting over
- For example, `cumsum` takes the cumulative sum of a vector. See `?cumsum` for similar functions
```{r}
cumsum(c(1,2,3))
```

```{r, tidy=F}
profits = tibble(
  day = c(1,2,3,4),
  profit = c(12, 40, 19, 13)
)
```

```{r, tidy=F}
profits %>%
  mutate(best_day_to_date = cumsum(profit))
```

Turning any function into a cumulative function
===

- you can use `slider::slide_vec()` to turn any function that accepts a vector and returns a number into a cumulative function
- Use `.before=Inf` to achieve this
```{r, tidy=F}
library(slider) # imports slide_vec() function

profits %>%
  mutate(profit_to_date = slide_vec(profit, sum, .before=Inf))
```

- it is usually better (computationally faster) to use a built-in cumulative function (e.g. `cumsum()`), but if none exists this is a great solution

Turning any function into a cumulative function
===
- If the function you want to transform takes additional arguments, you can give those to `slide_vec` and it will pass them through for you
```{r, tidy=F}
tibble(
  day = c(1,2,3,4),
  profit = c(12, 40, NA, 13)
) %>%
  mutate(profit_to_date = slide_vec(profit, mean, .before=Inf, na.rm=T))
```

Exercise: maximum temperature to-date
===
type:prompt

```{r, warning=F, message=F}
# install.packages("devtools")
library("devtools")
# install_github("Ram-N/weatherData")
library(weatherData)
library(lubridate)
data(SFO2013)
```

```{r, tidy=F, message=F}
sfo = SFO2013 %>%
  transmute( # mutate, but drops all other columns
    time = ymd_hms(Time), 
    temp = Temperature
  ) %>%
  group_by(day = date(time)) %>%
  summarize(max_temp = max(temp))
```

Starting with this `sfo` dataframe that I've prepared for you, add a column that has the maximum temperature in the past 30 days relative to the day indicated in that row

Column-wise operations
===
type: section

Repeating operations on columns
===
```{r, tidy=F}
df = tibble(
  a = rnorm(10),
  b = rnorm(10),
  c = rnorm(10),
  g = rbinom(10,1,0.5)
)
```

- Let's say we have these data and we want to take the mean of each column `a`, `b`, and `c` within the groups `g`. 
- One way to do it is with a normal summarize:

```{r, tidy=F, message=F}
df %>%
  group_by(g) %>%
  summarize(
    mean_a = mean(a),
    mean_b = mean(b),
    mean_b = mean(c)
  )
```


***

- Copy-pasting code like this frequently creates errors and bugs that are hard to see
- It's even worse if you want to do multiple summaries

```{r, tidy=F, message=F}
df %>%
  group_by(g) %>%
  summarize(
    mean_a = mean(a),
    mean_b = mean(b),
    mean_b = mean(c),
    median_a = median(a),
    median_b = median(b),
    median_c = median(c)
  )
```

Columnwise operations
===

- The solution is to use `across()` in your summarize:
```{r, tidy=F, message=F}
df %>%
  group_by(g) %>%
  summarize(across(c(a,b,c), mean))
```

- The first argument to `across()` is a selection of columns. You can use anything that would work in a `select()` here

*** 

- The second argument is the function you'd like to apply to each column. You can provide multiple functions by wrapping them in a "`list()`". Lists are like vectors but their elements can be of different types and each element has a name (more on that later)

```{r, tidy=F, message=F}
fns = list(
  avg=mean, 
  max=max
)

df %>%
  group_by(g) %>%
  summarize(across(c(a,b), fns))
```

- see `?across()` to find out how to control how these columns get named in the output

Columnwise operations with where()
===
```{r, tidy=F}
df = tibble(
  a = rnorm(10),
  b = rnorm(10),
  c = as.character(rnorm(10)),
  g = rbinom(10,1,0.5)
)
```

- Sometimes its nice to apply a transformation to all columns of a given type or all columns that match some condition
- `where()` is a handy function for that

```{r, tidy=F, message=F}
df %>%
  group_by(g) %>%
  summarize(across(where(is.numeric), mean))
```

Columnwise mutate
===
```{r, tidy=F}
df = tibble(
  a = rnorm(10),
  b = rnorm(10),
  c = as.character(rnorm(10)),
  g = rbinom(10,1,0.5)
)
```

- `across()` works with any `dplyr` "verb", including `mutate()`:

```{r, tidy=F, message=F}
df %>%
  mutate(across(where(is.character), as.numeric))
```

Columnwise mutate
===
- Most often you will need to write your own mini function to do what you want. To do that you put `~` before your expression and use `.` where you would put the name of the column

```{r, tidy=F, message=F}
df %>%
  mutate(across(
    a:b,                      # columns to mutate
    ~ . - lag(.),           # function to mutate them with
    .names = '{col}_offset'   # how to name the outputs
  ))
```

- Note that I've also used the `.names` argument to control how the output columns get named

Exercise: Filtering out or replacing NAs
===
type: prompt

```{r, message=F, warning=F}
# install.packages('nycflights13')
library(nycflights13)
# glimpse(flights)
```

1. Replacing NAs with some other value is a very common operation so it gets its own function: `replace_na()`. Use this function to replace all `NA`s present in any numeric column of the flights dataset with `0`s
2. Instead of replacing these values, we may want to filter them all out instead. Starting with the original data, use `filter()` and `across()` to remove all rows from the data that have any `NA`s in any column. Recall that `is.na()` checks which elements in a vector are `NA`.

Tidy data: rearranging a data frame
============================================================
type: section

Messy data
============================================================
- Sometimes data are organized in a way that makes it difficult to compute in a vector-oriented way. For example, look at this dataset:

```{r}
head(relig_income,2)
```

- the values in the table represent how many survey respondents were of each religion and income bracket.
- How could I use ggplot to make this plot? It's hard!

```{r, echo=F, warning=F}
library(stringr)
library(ggridges)

clean = relig_income %>%
  pivot_longer(-religion, names_to="income", values_to="count") %>%
  mutate(income = ifelse(income=="Don't know/refused", NA, income)) %>%
  mutate(
    income_lower = str_extract(income, '(>150k)|(^\\$[0-9]+)'),
    income_upper = str_extract(income, '(<\\$10k)|([\\-][0-9]+)'),
  ) %>%
  mutate(across(
    starts_with('income_'), 
    ~as.numeric(str_extract(.,'[0-9]+'))
  )) %>%
  mutate(
    income_lower = if_else(!is.na(income_upper) & is.na(income_lower), -Inf, income_lower),
    income_upper = if_else(!is.na(income_lower) & is.na(income_upper), Inf, income_upper)
  ) %>%
  mutate(income = fct_reorder(income, income_lower)) %>%
  group_by(religion) %>%
  mutate(freq = count/sum(count))
```

```{r, echo=F, warning=F, fig.width=20, fig.height=5}
clean %>%
  filter(religion %in% c("Muslim", "Jewish", "Hindu", "Buddhist", "Catholic", "Atheist", "Mainline Prot")) %>%
ggplot() +
  geom_bar(aes(x=income, y=count, fill=religion), stat='identity')
```

Messy data
===
```{r}
head(relig_income,3)
```
- One of the problems with the way these data are formatted is that the income level, which is a property of a particular population, is stuck into the names of the columns. 
- Because of this, it's also not obvious what the numbers in the table mean (although we know they are counts)

Tidy data
===
- Here's a better way to organize the data:
```{r, echo=F}
tidy = relig_income %>%
  pivot_longer(-religion, names_to="income", values_to="count") 
head(tidy)
```

This data is *tidy*. Tidy data follows three precepts:

1. each "variable" has its own dedicated column
2. each "observation" has its own row
3. each type of observational unit has its own data frame

In our example, each the **observations** are different **populations**, each of which has an associated _religion_, _income_, and _count_. These are the _variables_ that are measured about the population. 

Tidy data
===

Tidy data is easy to work with.

```{r, tidy=F, warning=F, fig.width=20, fig.height=5}
tidy %>%
    filter(religion %in% c("Muslim", "Jewish", "Hindu", "Buddhist", "Catholic", "Atheist", "Mainline Prot")) %>%
ggplot() +
  geom_bar(aes(x=income, y=count, fill=religion), stat='identity')
```

Tidying data with pivot_longer()
===

- `tidyr::pivot_longer()` is the function you will most often want to use to tidy your data
```{r, tidy=F}
relig_income %>%
  pivot_longer(-religion, names_to="income", values_to="count") %>%
  head(3)
```

- the three important arguments are: a) a selection of columns, b) the name of the new key column, and c) the name of the new value column

![](https://swcarpentry.github.io/r-novice-gapminder/fig/14-tidyr-fig3.png)

Exercise: cleaning GTEX
===
type:prompt

```{r, message=F, warning=F}
gtex = read_tsv('https://raw.githubusercontent.com/alejandroschuler/r4ds-courses/advance-2020/data/gtex.tissue.zscores.advance2020.txt')
```

Use the GTEX data to reproduce the following plot:

```{r, echo=F, warning=F, fig.width=20}
gtex %>%
  filter(
    Ind %in% c('GTEX-11GSP', 'GTEX-11DXZ'),
    Gene %in% c('A2ML1', 'A3GALT2', 'A4GALT')
  ) %>%
  pivot_longer(
    Blood:Liver, 
    names_to="tissue", 
    values_to='expression'
  ) %>%
ggplot() +
  geom_point(aes(x=Gene, y=expression, color=tissue), size=10) + 
  facet_wrap(~Ind)
```

The individuals and genes of interest are `c('GTEX-11GSP', 'GTEX-11DXZ')` and `c('A2ML1', 'A3GALT2', 'A4GALT')`, respectively.

"Messy" data is relative and not always bad
===

```{r, echo=F}
wide_mice = tibble(
  mouse = c(1,2,3,4),
  weight_before = rnorm(4, 10, 2),
  weight_after = rnorm(4, 11, 2),
)
wide_mice
```

```{r, tidy=F}
wide_mice %>%
  mutate(weight_gain = weight_after - weight_before) %>%
  select(mouse, weight_gain)
```

***

```{r, echo=F}
long_mice = wide_mice %>%
  pivot_longer(-mouse, names_to="time", values_to="weight", names_prefix="weight_") %>%
  mutate()
long_mice
```

```{r, tidy=F}
long_mice %>%
  group_by(mouse) %>%
  mutate(weight_gain = weight - lag(weight)) %>%
  filter(!is.na(weight_gain)) %>%
  select(mouse, weight_gain)
```

Pivoting wider
============================================================
- As we saw with the mouse example, sometimes our data is actually easier to work with in the "wide" format. 
- wide data is also often nice to make tables for presentations, or is (unfortunately) sometimes required as input for other software packages
- To go from long to wide, we use `pivot_wider()`:

```{r, tidy=F}
long_mice
```

***

```{r, tidy=F}
long_mice %>% 
  pivot_wider(
    names_from = time, 
    values_from = weight
  )
```

Names prefix
============================================================

```{r, tidy=F}
long_mice
```

***

- you can use `names_prefix` to make variables names that are more clear in the result

```{r, tidy=F}
long_mice %>% 
  pivot_wider(
    names_from = time, 
    values_from = weight,
    names_prefix = "weight_"
  ) %>% head(2)
```

- this can also be used to _remove_ a prefix when going from wide to long:

```{r, tidy=F, eval=F}
wide_mice %>% 
  pivot_longer(
    -mouse
    names_to = "time",
    values_to = "weight",
    names_prefix = "weight_"
  )
```

Exercise: creating a table
===
type: prompt

Use the GTEX data to make the following table:

```{r, echo=F, message=F}
print("Number of missing tissues:")
gtex %>%
  filter(
    Ind %in% c('GTEX-11GSP', 'GTEX-11DXZ'),
    Gene %in% c('A2ML1', 'A3GALT2', 'A4GALT')
  ) %>% 
  pivot_longer(Lung:Liver, names_to='tissue', values_to='expression') %>%
  group_by(Ind, Gene) %>%
  summarize(n_missing_tissues = sum(is.na(expression))) %>%
  pivot_wider(names_from=Gene, values_from=n_missing_tissues)
```

The numbers in the table are the number of tissues in each individual for which the gene in question was missing.

Multi-pivoting
===
incremental: true


Have a look at the following data. How do you think we might want to make it look?

```{r, tidy=F}
data(anscombe)
anscombe
```

The problem here is that the column names contain two pieces of data:

1. the coordinate (`x` or `y`)
2. some group that it came from (`1`, `2`, `3`, or `4`)

Our use of `pivot_longer` has so far been to extract a single piece of information from the column name

Multi-pivoting
===
- Turns out this problem can be tackled too:

```{r, tidy=F}
anscombe %>%
  pivot_longer(everything(),
    names_pattern = "(.)(.)", # a "regular expression"- we'll learn about these later
    names_to = c(".value", "group")
  ) 
```

- We won't dig into this, but you should know that almost any kind of data-tidying problem can be solved with some combination of the functions in the `tidyr` package. 
- See the online [docs and vignettes](https://tidyr.tidyverse.org/articles/pivot.html) for more info

